{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9d08f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb905850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 3.89kB [00:00, 9.77MB/s]\n",
      "Downloading readme: 7.84kB [00:00, 14.9MB/s]\n",
      "Generating train split: 5780 examples [00:00, 63773.91 examples/s]\n",
      "Filter: 100%|██████████| 5780/5780 [00:00<00:00, 225206.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5198', 'data_id': 'swe_news_2019_10K', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe_news_2019_10K.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '10K'}\n",
      "{'id': '5199', 'data_id': 'swe_news_2019_30K', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe_news_2019_30K.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '30K'}\n",
      "{'id': '5200', 'data_id': 'swe_news_2019_100K', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe_news_2019_100K.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '100K'}\n",
      "{'id': '5201', 'data_id': 'swe_news_2019_300K', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe_news_2019_300K.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '300K'}\n",
      "{'id': '5202', 'data_id': 'swe_news_2019_1M', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe_news_2019_1M.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '1M'}\n",
      "{'id': '5218', 'data_id': 'swe-se_web_2019_10K', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe-se_web_2019_10K.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '10K'}\n",
      "{'id': '5219', 'data_id': 'swe-se_web_2019_30K', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe-se_web_2019_30K.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '30K'}\n",
      "{'id': '5220', 'data_id': 'swe-se_web_2019_100K', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe-se_web_2019_100K.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '100K'}\n",
      "{'id': '5221', 'data_id': 'swe-se_web_2019_300K', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe-se_web_2019_300K.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '300K'}\n",
      "{'id': '5222', 'data_id': 'swe-se_web_2019_1M', 'url': 'https://downloads.wortschatz-leipzig.de/corpora/swe-se_web_2019_1M.tar.gz', 'language': 'Swedish', 'language_short': 'swe', 'year': '2019', 'size': '1M'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This can be used to find the data_id of different corpora, just change language or year.\n",
    "links = load_dataset(\"imvladikon/leipzig_corpora_collection\", \"links\", split=\"train\", trust_remote_code=True)\n",
    "\n",
    "ds = links.filter(lambda x: x[\"language\"] == \"Swedish\" and x[\"year\"] == \"2019\")\n",
    "\n",
    "for sample in ds:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86aa398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.1\n"
     ]
    }
   ],
   "source": [
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d894b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many of the 21 corpora have sizes: 10K, 30K, 100K, 300K, 1M but not all of them\n",
    "# All except Slovak was available for 2019\n",
    "# Change the ids below to try different sizes or years\n",
    "data_ids = [\n",
    "    \"bul_news_2019_10K\",\n",
    "    \"ces_news_2019_10K\",\n",
    "    \"dan_news_2019_10K\",\n",
    "    \"deu_news_2019_10K\",\n",
    "    \"ell_news_2019_10K\",\n",
    "    \"eng_news_2019_10K\",\n",
    "    \"est_news_2019_10K\",\n",
    "    \"fin_news_2019_10K\",\n",
    "    \"fra_news_2019_10K\",\n",
    "    \"hun_news_2019_10K\",\n",
    "    \"ita_news_2019_10K\",\n",
    "    \"lav_news_2019_10K\",\n",
    "    \"lit_news_2019_10K\",\n",
    "    \"nld_news_2019_10K\",\n",
    "    \"pol_news_2019_10K\",\n",
    "    \"por_news_2019_10K\",\n",
    "    \"ron_news_2019_10K\",\n",
    "    \"slk_news_2020_10K\",\n",
    "    \"slv_news_2019_10K\",\n",
    "    \"spa_news_2019_10K\",\n",
    "    \"swe_news_2019_10K\"\n",
    "]\n",
    "\n",
    "language_map = {\n",
    "    \"bul\": \"Bulgarian\",\n",
    "    \"ces\": \"Czech\",\n",
    "    \"dan\": \"Danish\",\n",
    "    \"deu\": \"German\",\n",
    "    \"ell\": \"Greek\",\n",
    "    \"eng\": \"English\",\n",
    "    \"est\": \"Estonian\",\n",
    "    \"fin\": \"Finnish\",\n",
    "    \"fra\": \"French\",\n",
    "    \"hun\": \"Hungarian\",\n",
    "    \"ita\": \"Italian\",\n",
    "    \"lav\": \"Latvian\",\n",
    "    \"lit\": \"Lithuanian\",\n",
    "    \"nld\": \"Dutch\",\n",
    "    \"pol\": \"Polish\",\n",
    "    \"por\": \"Portuguese\",\n",
    "    \"ron\": \"Romanian\",\n",
    "    \"slk\": \"Slovak\",\n",
    "    \"slv\": \"Slovenian\",\n",
    "    \"spa\": \"Spanish\",\n",
    "    \"swe\": \"Swedish\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e7b713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets version:  2.19.1\n"
     ]
    }
   ],
   "source": [
    "# I had to \"pip install datasets==2.19.1\" for this to work \n",
    "print(\"datasets version: \", datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe582a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 2.16M/2.16M [00:00<00:00, 2.45MB/s]\n",
      "Generating train split: 8807 examples [00:00, 114442.68 examples/s]\n",
      "Downloading data: 100%|██████████| 2.20M/2.20M [00:00<00:00, 2.85MB/s]\n",
      "Generating train split: 7691 examples [00:00, 108078.45 examples/s]\n",
      "Downloading data: 100%|██████████| 2.22M/2.22M [00:01<00:00, 1.54MB/s]\n",
      "Generating train split: 9140 examples [00:00, 122872.78 examples/s]\n",
      "Downloading data: 100%|██████████| 2.31M/2.31M [00:01<00:00, 2.19MB/s]\n",
      "Generating train split: 9494 examples [00:00, 68452.59 examples/s]\n",
      "Downloading data: 100%|██████████| 2.74M/2.74M [00:00<00:00, 3.63MB/s]\n",
      "Generating train split: 9139 examples [00:00, 111320.76 examples/s]\n",
      "Downloading data: 100%|██████████| 2.76M/2.76M [00:00<00:00, 3.12MB/s]\n",
      "Generating train split: 8455 examples [00:00, 115047.20 examples/s]\n",
      "Downloading data: 100%|██████████| 2.12M/2.12M [00:01<00:00, 1.67MB/s]\n",
      "Generating train split: 8144 examples [00:00, 115901.63 examples/s]\n",
      "Downloading data: 100%|██████████| 1.81M/1.81M [00:00<00:00, 2.90MB/s]\n",
      "Generating train split: 9644 examples [00:00, 114704.54 examples/s]\n",
      "Downloading data: 100%|██████████| 2.58M/2.58M [00:00<00:00, 3.23MB/s]\n",
      "Generating train split: 9024 examples [00:00, 106611.12 examples/s]\n",
      "Downloading data: 100%|██████████| 2.44M/2.44M [00:00<00:00, 3.17MB/s]\n",
      "Generating train split: 8410 examples [00:00, 106370.95 examples/s]\n",
      "Downloading data: 100%|██████████| 2.56M/2.56M [00:00<00:00, 2.80MB/s]\n",
      "Generating train split: 8961 examples [00:00, 118147.74 examples/s]\n",
      "Downloading data: 100%|██████████| 2.37M/2.37M [00:01<00:00, 1.59MB/s]\n",
      "Generating train split: 8894 examples [00:00, 105203.59 examples/s]\n",
      "Downloading data: 100%|██████████| 2.10M/2.10M [00:00<00:00, 2.71MB/s]\n",
      "Generating train split: 8432 examples [00:00, 98457.07 examples/s]\n",
      "Downloading data: 100%|██████████| 1.88M/1.88M [00:00<00:00, 2.84MB/s]\n",
      "Generating train split: 8983 examples [00:00, 125313.66 examples/s]\n",
      "Downloading data: 100%|██████████| 2.12M/2.12M [00:01<00:00, 1.84MB/s]\n",
      "Generating train split: 9313 examples [00:00, 121273.39 examples/s]\n",
      "Downloading data: 100%|██████████| 2.62M/2.62M [00:00<00:00, 3.05MB/s]\n",
      "Generating train split: 8758 examples [00:00, 119646.00 examples/s]\n",
      "Downloading data: 100%|██████████| 2.64M/2.64M [00:01<00:00, 2.63MB/s]\n",
      "Generating train split: 7800 examples [00:00, 119157.67 examples/s]\n",
      "Downloading data: 100%|██████████| 2.23M/2.23M [00:00<00:00, 2.60MB/s]\n",
      "Generating train split: 8315 examples [00:00, 117878.06 examples/s]\n",
      "Downloading data: 100%|██████████| 2.39M/2.39M [00:00<00:00, 3.20MB/s]\n",
      "Generating train split: 8315 examples [00:00, 117037.84 examples/s]\n",
      "Downloading data: 100%|██████████| 2.89M/2.89M [00:00<00:00, 3.49MB/s]\n",
      "Generating train split: 9278 examples [00:00, 123029.20 examples/s]\n",
      "Downloading data: 100%|██████████| 1.99M/1.99M [00:00<00:00, 2.78MB/s]\n",
      "Generating train split: 9594 examples [00:00, 128310.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def get_multi_language_dataset(data_ids):\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    for data_id in data_ids:\n",
    "        ds = load_dataset(\"imvladikon/leipzig_corpora_collection\", data_id, split=\"train\", trust_remote_code=True)\n",
    "        language_code = data_id.split('_')[0]\n",
    "        label = language_map[language_code]\n",
    "        ds = ds.add_column(\"label\", [label] * len(ds))\n",
    "        datasets.append(ds)\n",
    "\n",
    "    full_dataset = concatenate_datasets(datasets)\n",
    "\n",
    "    return full_dataset\n",
    "\n",
    "full_ds = get_multi_language_dataset(data_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da32e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:  Dataset({\n",
      "    features: ['id', 'sentence', 'label'],\n",
      "    num_rows: 184591\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# dataset information\n",
    "print(\"Dataset info: \", full_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377bae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (184591, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape: \", full_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3dc650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  {'Polish', 'Dutch', 'Hungarian', 'Danish', 'Portuguese', 'Slovak', 'Finnish', 'Latvian', 'Romanian', 'German', 'Estonian', 'Swedish', 'English', 'Bulgarian', 'Slovenian', 'Spanish', 'French', 'Greek', 'Lithuanian', 'Czech', 'Italian'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels: \", set(full_ds[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f8f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "133497 {'id': '1016', 'sentence': 'A mulher sofreu ferimentos leves, chegou a ser atendida e foi levada ao hotel.', 'label': 'Portuguese'}\n",
      "113745 {'id': '9299', 'sentence': 'Vakcina nuo meningokokinės B tipo infekcijos buvo Europoje užregistruota 2013-aisiais, o Lietuvoje ja pasiskiepyti galima jau nuo 2014-ųjų.', 'label': 'Lithuanian'}\n",
      "62208 {'id': '1339', 'sentence': 'Hän antoi Ruotsi-ottelun voitto-osumastaan varauksettomasti tunnustusta hienon syötön antaneelle Teemu Turuselle.', 'label': 'Finnish'}\n",
      "82878 {'id': '4002', 'sentence': 'Az izraeli és az egyiptomi hírszerzés jelentései szerint a Hamasz támadásokat tervez Törökország területéről.', 'label': 'Hungarian'}\n",
      "11633 {'id': '3654', 'sentence': 'Michel je teprve třetím stálým předsedou rady a po Hermanu van Rompuyovi druhým Belgičanem v této funkci.', 'label': 'Czech'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples:\")\n",
    "for i in range(5):\n",
    "    j = np.random.randint(0, len(full_ds))\n",
    "    print(j, full_ds[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appliedAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
